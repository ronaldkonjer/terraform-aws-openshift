# OpenShift Inventory Template.
# Note that when the infrastructure is generated by Terraform, this file is
# expanded into './inventory.cfg', based on the rules in:
#
#   ./modules/openshift/08-inventory.tf

# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
etcd

# Set variables common for all OSEv3 hosts
[OSEv3:vars]
# SSH user, this user should allow ssh based auth without requiring a password
ansible_ssh_user=ec2-user

# If ansible_ssh_user is not root, ansible_become must be set to true
ansible_become=true

# Deploy OpenShift origin.
deployment_type=origin
#openshift_deployment_type=origin
#openshift_image_tag="v3.7.1"
#openshift_pkg_version="-3.7"
#containerized=false

# logging
openshift_logging_install_logging=true

# We need a wildcard DNS setup for our public access to services, fortunately
# we can use the superb xip.io to get one for free.
openshift_public_hostname=${public_hostname}
openshift_master_default_subdomain=${public_hostname}

# Use an htpasswd file as the indentity provider.
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '/etc/origin/master/htpasswd'}]

# disable check on package version
openshift_disable_check=package_version

# Uncomment the line below to enable metrics for the cluster.
openshift_metrics_install_metrics=true

# Use API keys rather than instance roles so that tenant containers don't get
# Openshift's EC2/EBS permissions
openshift_cloudprovider_kind=aws
openshift_clusterid=${cluster_id}
openshift_cloudprovider_aws_access_key=${access_key}
openshift_cloudprovider_aws_secret_key=${secret_key}

# Docker additional external insecure repository
openshift_docker_additional_registries=docker-CG.cgnet.nl 
openshift_docker_insecure_registries=docker-CG.cgnet.nl 

# Upgrade Hooks
#
# Hooks are available to run custom tasks at various points during a cluster
# upgrade. Each hook should point to a file with Ansible tasks defined. Suggest using
# absolute paths, if not the path will be treated as relative to the file where the
# hook is actually used.

# Define an additional dnsmasq.conf file to deploy to /etc/dnsmasq.d/openshift-ansible.conf
# This is useful for POC environments where DNS may not actually be available yet or to set
# options like 'strict-order' to alter dnsmasq configuration.
openshift_node_dnsmasq_additional_config_file=${dnsmasq_conf}

# additional cors origins
osm_custom_cors_origins=['sc.*','s3.*']

# LDAP auth
openshift_master_identity_providers=[{'name': 'ldap_provider','challenge': 'true','login': 'true','kind': 'LDAPPasswordIdentityProvider','attributes': {'id': ['dn'],'email': ['mail'],'name': ['cn'],'preferredUsername': ['uid']},'bindDN': 'cn=Manager,dc=cgnet,dc=nl','bindPassword': 'J]Nd6dIS$]JD','insecure': 'true','url': 'ldap://zd005.cgnet.nl:389/cn=Manager,dc=cgnet,dc=nl?uid'}]

# Create the masters host group. Note that due do:
#   https://github.com/dwmkerr/terraform-aws-openshift/issues/40
# We cannot use the internal DNS names (such as master.openshift.local) as there
# is a bug with the installer when using the AWS cloud provider.
[masters]
${master_hostname} openshift_hostname=${master_hostname}

# host group for etcd
[etcd]
${master_hostname} openshift_hostname=${master_hostname}

# host group for nodes, includes region info
[nodes]
${master_hostname} openshift_hostname=${master_hostname} openshift_node_labels="{'region': 'infra', 'zone': 'default'}" openshift_schedulable=true
${node1_hostname} openshift_hostname=${node1_hostname} openshift_node_labels="{'region': 'primary', 'zone': 'east'}"
${node2_hostname} openshift_hostname=${node2_hostname} openshift_node_labels="{'region': 'primary', 'zone': 'west'}"


